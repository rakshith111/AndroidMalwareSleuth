import os
import requests
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm


def download_file(url, dest_folder, pbar):
    try:
        response = requests.get(url, timeout=10, stream=True)
        file_name = os.path.basename(url)

        if not os.path.exists(dest_folder):
            os.makedirs(dest_folder)

        with open(os.path.join(dest_folder, file_name), 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
        pbar.update(1)
        return None
    except Exception as e:
        print(f"Error downloading {url}: {e}")
        pbar.update(1)
        return file_name


def check_existing_files(urls, dest_folder):
    if os.path.exists(dest_folder):
        base_addres = urls[1].split('/')[:-1]
        base_address = "/".join(base_addres)

        existing_files = set(f for f in os.listdir(dest_folder))

        target_files = set([urls.split('/')[-1].split('?')[0]
                           for urls in urls])

        urls = [base_address + '/' + f
                for f in target_files - existing_files]
        print(f"Found {len(existing_files)} existing files.")
        print(f"Downloading {len(urls)} new files.")

    return urls


def main(input_file, num_threads=10):
    if not os.path.exists("Scrapper\\downloaded"):
        os.makedirs("Scrapper\\downloaded")
    dest_folder = os.path.join(
        "Scrapper\\downloaded", os.path.splitext(input_file)[0].split('\\')[-1])
    print(f"Downloading {input_file} to {dest_folder}...")
    with open(input_file) as f:
        urls = [line.strip() for line in f.readlines()]

    urls = check_existing_files(urls, dest_folder)

    failed_files = []

    with ThreadPoolExecutor(max_workers=num_threads) as executor:
        with tqdm(total=len(urls), desc="Downloading files") as pbar:
            futures = [executor.submit(
                download_file, url, dest_folder, pbar) for url in urls]
            for future in futures:
                failed_file = future.result()
                if failed_file:
                    failed_files.append(failed_file)

    print("Download complete.")

    # Delete failed files
    for failed_file in failed_files:
        file_path = os.path.join(dest_folder, failed_file)
        if os.path.exists(file_path):
            os.remove(file_path)
            print(f"Deleted failed file: {failed_file}")


if __name__ == "__main__":
    num_threads = 15
    for i in range(2, 6):
        main(rf"Scrapper\riskware_failed_{i}.txt", num_threads)
