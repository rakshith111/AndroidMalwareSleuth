import re
import os
def extract_patterns(input_file, output_file, pattern):
    with open(input_file, 'r') as infile:
        content = infile.read()

    matches = re.findall(pattern, content)

    with open(output_file, 'w') as outfile:
        for match in matches:
            outfile.write(match + '\n')
if __name__ == "__main__":
    input_file = os.path.join(r"Scrapper\Reports\temp.txt")
    base_file=os.path.join(r"Scrapper\Reports\generated_links.txt")
    base_url=input("Enter the BASE URL: ")
    pattern = r'[A-Fa-f0-9]{64}'
    output_file = os.path.join(r"Scrapper\Reports\temp_caught.txt")
    extract_patterns(input_file, output_file, pattern)
    with open(output_file, 'r') as f:
        main_set=set(f.read().splitlines())
    with open(base_file, 'w') as f:
        for i in main_set:
            f.write(base_url+i+".tar.gz")
            f.write("\n")
'''
copy paste all the links  which are failed to extract properly from the generated report 
and paste it in temp.txt file and run this script
THis will generate a new file with all the links which are not extracted properly
and provide the new file to the downloader script


'''