import os
import tarfile
import os
import shutil
from shutil import make_archive
from tqdm import tqdm
import concurrent.futures


def extract_single_file(file, source_folder, processed_folder, report_file):
    try:
        tar_file_path = os.path.join(source_folder, file)
        with tarfile.open(tar_file_path, 'r:gz', errors="ignore") as tar:
            json_file_name = 'sample_for_analysis.apk.static.json'
            json_file = None

            for tarinfo in tar:
                if tarinfo.name.endswith(json_file_name):
                    json_file = tar.extractfile(tarinfo)
                    break

            if json_file:
                dest_folder = os.path.join(
                    processed_folder, os.path.splitext(file)[0] + '.json')
                with open(dest_folder, 'wb') as dest_file:
                    dest_file.write(json_file.read())
                return f"Processed: {file}\n"
            else:
                return f"Failed: {file} - Error: {json_file_name} not found\n"

    except tarfile.ReadError as e:
        return f"Failed: {file} - Error: {e}\n"
    except Exception as e:
        return f"Failed: {file} - Error: {e}\n"


def make_archive(source, destination, format='zip',input_name=None):
    # Move report
    new_report_path = os.path.join(processed_folder, os.path.basename(report_file))
    shutil.move(report_file, new_report_path)
    name = f"Processed_{input_name}"
    archive_from = os.path.dirname(source)
    archive_to = os.path.basename(source.strip(os.sep))
    print(
        f'Source: {source}\nDestination: {destination}\n')
    shutil.make_archive(name, format, archive_from, archive_to)
    shutil.move('%s.%s' % (name, format), destination)

# Call the function after processing the files


def extract_tar_gz_files(source_folder, processed_folder, report_file):
    tar_gz_files = []
    for root, dirs, files in os.walk(source_folder):
        for file in files:
            if file.endswith('.tar.gz'):
                tar_gz_files.append(file)

    with concurrent.futures.ThreadPoolExecutor() as executor:
        results = list(tqdm(executor.map(extract_single_file, tar_gz_files, [source_folder] * len(tar_gz_files), [
                       processed_folder] * len(tar_gz_files), [report_file] * len(tar_gz_files)), total=len(tar_gz_files)))

    with open(report_file, 'w') as report:
        for result in results:
            report.write(result)


for i in range(1, 9):
    source_folder = rf'Scrapper\downloaded\sms\sms_part{i}'
    name = source_folder.split("\\")[-1]
    print(f"Processing {name}...")
    processed_folder = os.path.join(source_folder, 'Processed')
    report_file = os.path.join(source_folder, f'{name}_report.txt')

    if not os.path.exists(processed_folder):
        os.makedirs(processed_folder)

    extract_tar_gz_files(source_folder, processed_folder, report_file)
    make_archive(processed_folder, 'Scrapper\downloaded',input_name=name)
