import os
import sys
import csv
import json
import argparse
from typing import List, Dict, Tuple, Union

current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

from FeatureExtraction.libs._base_logger import logger, error_logger
from FeatureExtraction.libs.color import bcolors

def load_headers(file_path: str) -> List[str]:
    """
    Load headers from a CSV file.

    :param file_path: Path to the CSV file containing headers.
    :return: A list of headers.
    """
    headers = []
    with open(file_path, "r") as f:
        reader = csv.reader(f)
        for row in reader:
            if row:
                headers.append(row[0])
    headers = headers[1:-1]
    return headers


def check_csv_files_exist(file_paths: List[str]) -> bool:
    """
    Check if all CSV files in the given list exist.

    :param file_paths: List of file paths to CSV files.
    :return: True if all files exist, False otherwise.
    """
    for path in file_paths:
        if not os.path.exists(path):
            error_logger.error(
                f"{bcolors.FAIL}CSV file '{path}' does not exist.{bcolors.ENDC}")
            return False
    return True


def vectorize_data(data: Dict[str, int], headers: List[str], use_count: bool = False, convert_to_dict: bool = True) -> Union[List[int], Dict[str, int]]:
    """
    Generate a vectorized array for the given data using the specified headers.

    :param data: A dictionary containing the data to be vectorized.
    :param headers: A list of headers to be used for vectorization.
    :param use_count: Whether to use the count values in the data (default: False).
    :param convert_to_dict: Whether to convert the output into a dictionary with matching keys (default: True).
    :return: A vectorized array or dictionary.
    """
    if convert_to_dict:
        vector = {}
        for header in headers:
            vector[header] = data.get(
                header, 0) if use_count else 1 if header in data else 0
        return vector
    else:
        vector = [0] * len(headers)
        for key, count in data.items():
            if key in headers:
                vector[headers.index(key)] = count if use_count else 1
        return vector


def process_files(input_dir: str, convert_to_dict: bool) -> None:
    """
    Process JSON files in the given directory and generate vectorized arrays.

    :param input_dir: Path to the input directory.
    :param convert_to_dict: Whether to convert the output into a dictionary with matching keys.
    :return: None.
    """
    if not os.path.exists(input_dir):
        error_logger.error(
            f"{bcolors.FAIL}Input directory '{input_dir}' does not exist.{bcolors.ENDC}")
        return
    if not os.listdir(input_dir):
        error_logger.error(
            f"{bcolors.FAIL}Input directory '{input_dir}' is empty.{bcolors.ENDC}")
        return

    intents_headers = load_headers(header_csv_files[0])
    permissions_headers = load_headers(header_csv_files[1])
    merged_headers = load_headers(header_csv_files[2])
    api_headers = load_headers(header_csv_files[3])
    api_files_dir = os.path.join(input_dir, "APIs")
    intent_permission_files_dir = os.path.join(input_dir, "IntentPermission")

    for json_file in os.listdir(api_files_dir):
        if json_file.endswith("_API.json"):
            json_file_path = os.path.join(api_files_dir, json_file)
            with open(json_file_path, "r") as file:
                api_data = json.load(file)
            api_vector = vectorize_data(
                api_data, api_headers, use_count=False, convert_to_dict=convert_to_dict)
            api_vector["class"]=None
            logger.info(
                f"{bcolors.OKGREEN}API Vector for {json_file}:{bcolors.ENDC} \n{bcolors.OKBLUE} {api_vector}{bcolors.ENDC}\n")

    for json_file in os.listdir(intent_permission_files_dir):
        if json_file.endswith("_IntentPerms.json"):
            json_file_path = os.path.join(
                intent_permission_files_dir, json_file)
            with open(json_file_path, "r") as file:
                intent_permission_data = json.load(file)
            # Intents
            intents_vector = vectorize_data(
                intent_permission_data["intents"], intents_headers, convert_to_dict=convert_to_dict)
            intents_vector["class"]=None
            logger.info(
                f"{bcolors.OKGREEN}\n\nIntents Vector for {json_file}:{bcolors.ENDC} \n{bcolors.OKBLUE}{intents_vector}\n\n{bcolors.ENDC}\n")
            # Permissions
            permissions_vector = vectorize_data(
                intent_permission_data["permissions"], permissions_headers, convert_to_dict=convert_to_dict)
            permissions_vector["class"]=None
            logger.info(
                f"{bcolors.OKGREEN}\n\nPermissions Vector for {json_file}:{bcolors.ENDC}  \n{bcolors.OKBLUE} {permissions_vector}\n\n{bcolors.ENDC}\n")
            # Merged
            merged_vector = vectorize_data(
                {**intent_permission_data["intents"], **intent_permission_data["permissions"]}, merged_headers, convert_to_dict=convert_to_dict)
            merged_vector["class"]=None
            logger.info(
                f"{bcolors.OKGREEN}\n\nMerged Vector for {json_file}:{bcolors.ENDC} \n{bcolors.OKBLUE} {merged_vector}\n\n{bcolors.ENDC}\n")


if __name__ == "__main__":
    # You can replace these paths with the paths to your CSV files
    header_csv_files = [
        "ChimeraDataset\Headers\ChimeraDatasetIntent_headers.csv",
        "ChimeraDataset\Headers\ChimeraDatasetPermission_headers.csv",
        "ChimeraDataset\Headers\ChimeraDatasetMerged_headers.csv",
        "CICMalDroidDataset\MobFS_APIs_heads_mini.csv"
    ]

    if not check_csv_files_exist(header_csv_files):
        error_logger.error("Please Build the CSV files first.")
        exit(1)

    header_lists = [load_headers(csv_file) for csv_file in header_csv_files]

    parser = argparse.ArgumentParser(
        description="Generate vectorized arrays from JSON files.")
    parser.add_argument(
        "-i", "--input_dir", help="Path to the input directory", type=str, required=True)
    parser.add_argument(
        "-d", "--convert_to_dict", help="Whether to convert the output into a dictionary with matching keys (default: True)", type=bool, default=True)

    args = parser.parse_args()

    process_files(args.input_dir, args.convert_to_dict)
