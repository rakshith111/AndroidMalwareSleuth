import pandas as pd

# Load the datasets
load_features = pd.read_csv(
    'Datasets\Drebin\malware_dataset\original\dataset-features-categories.csv')
load_dataset = pd.read_csv(
    'Datasets\Drebin\malware_dataset\only_true_drebin.csv')


def modify_dataset(load_derbin):
    '''
    :param load_derbin: A DataFrame to be modified

    :return: None

    Rebinds the features to a format that can be used as column names
    '''
    modified_derbin = pd.DataFrame()
    # Check if the DataFrame is empty before iterating over columns
    if not load_derbin.empty:
        for col_name in load_derbin.columns:
            new_name = rebind_features(str(col_name).lower())
            modified_derbin[new_name] = load_derbin[col_name]

        modified_derbin.to_csv('modified_drebin.csv', index=False)
    else:
        print("Error: DataFrame is empty")


def rebind_features(string_input):
    '''
    :param string_input: A string to be modified

    :return: A modified string

    Rebinds the features to a format that can be used as column names
    '''
    if '/' in string_input:
        string_input = string_input.replace('/', 'slash')
    elif '.' in string_input:
        string_input = string_input.replace('.', 'dot')
    else:
        return string_input
    return string_input


def write_subdatasets(subdatasets, filename_prefix):
    '''
    :param subdatasets: A dictionary with keys as types and values as subdatasets
    :param filename_prefix: The prefix of the filename to be written

    :return: None   

    Writes the subdatasets to csv files
    '''
    for call_type in subdatasets:
        filename = f"{filename_prefix}_{call_type}.csv"
        subdatasets[call_type].to_csv(filename, index=False)
        print(f"{filename} written successfully.")


# Create a dictionary with keys as types and values as lists of corresponding calls
call_dict = {}
for _, row in load_features.iterrows():
    call = row['Call']
    call_type = row['TYPE']
    if call_type not in call_dict:
        call_dict[call_type] = []
    call_dict[call_type].append(call)


# Lowercase the keys and values
lowercase_dict = dict()
for k, v in call_dict.items():
    lowercase_dict[str(str(k).lower()).replace(" ", "_")] = [
        str(x).lower() for x in v]

# Rebind the features
for k, v in lowercase_dict.items():
    lowercase_dict[k] = [rebind_features(x) for x in v]

# Create subdatasets based on call types
subdatasets = {}
for call_type in lowercase_dict:
    subdatasets[call_type] = load_dataset[lowercase_dict[call_type]]
    subdatasets[call_type]['class'] = load_dataset['class']
# Print the size of each subdataset
for call_type in subdatasets:
    print(f'Subdataset for {call_type}: {subdatasets[call_type].shape}')


write_subdatasets(subdatasets, 'drebin-subdatasets')
