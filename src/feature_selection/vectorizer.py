
import os
import csv
import json
import sys
import argparse
from typing import List, Dict, Union

sys.path.append(
    os.path.dirname((os.path.dirname(os.path.abspath(__file__)))))
from libs._base_logger import logger, error_logger
from libs.color import bcolors

def load_headers(file_path: str) -> List[str]:
    '''  
    Load headers from a CSV file.
    Args:
        file_path (str): Path to the CSV file containing headers.

    Returns:
        List[str]:A list of headers.
    '''
    headers = []
    with open(file_path, "r") as f:
        reader = csv.reader(f)
        for row in reader:
            if row:
                headers.append(row[0])
    headers = headers[1:]
    return headers


def check_csv_files_exist(file_paths: List[str]) -> bool:
    '''Check if all CSV files in the given list exist.

    Args:
        file_paths (List[str]): List of file paths to CSV files.

    Returns:
        bool: True if all files exist, False otherwise.
    '''

    for path in file_paths:
        if not os.path.exists(path):
            error_logger.error(
                f"{bcolors.FAIL}CSV file '{path}' does not exist.{bcolors.ENDC}")
            return False
    return True


def vectorize_data(data: Dict[str, int], headers: List[str], use_count: bool = False, convert_to_dict: bool = True) -> Union[List[int], Dict[str, int]]:
    '''
    Vectorize the given data using the given headers.
    Args:
        data (Dict[str, int]): A dictionary containing the data to be vectorized.
        headers (List[str]): A list of headers to be used for vectorization.
        use_count (bool, optional): Whether to use the count values in the data. Defaults to False.
        convert_to_dict (bool, optional): Whether to convert the output into a dictionary with matching keys. Defaults to True.

    Returns:
        Union[List[int], Dict[str, int]]: A vectorized array or dictionary.
    '''
    if convert_to_dict:
        vector = {}
        for header in headers:
            vector[header] = data.get(
                header, 0) if use_count else 1 if header in data else 0
        return vector
    else:
        vector = [0] * len(headers)
        for key, count in data.items():
            if key in headers:
                vector[headers.index(key)] = count if use_count else 1
        return vector


def process_files(input_dir: str, convert_to_dict: bool, save_to_file: bool) -> List:
    '''
    Process JSON files in the given directory and generate vectorized arrays.

    Args:
        input_dir (str): Path to the input directory.
        convert_to_dict (bool): Whether to convert the output into a dictionary with matching keys.
        save_to_file (bool): Whether to save the output to a file.

    Returns:
        List: A list of vectorized arrays [api_vector, intents_vector, permissions_vector, merged_vector].
    '''
    header_csv_files = [
        r"src\dataset_heads\ChimeraDatasetIntent_headers.csv",
        r"src\dataset_heads\ChimeraDatasetPermission_headers.csv",
        r"src\dataset_heads\ChimeraDatasetMerged_headers.csv",
        r"src\dataset_heads\mapped_heads.csv"
    ]
    if not os.path.exists(input_dir):
        error_logger.error(
            f"{bcolors.FAIL}Input directory '{input_dir}' does not exist.{bcolors.ENDC}")
        return
    if not os.listdir(input_dir):
        error_logger.error(
            f"{bcolors.FAIL}Input directory '{input_dir}' is empty.{bcolors.ENDC}")
        return

    results = []
    intents_headers = load_headers(header_csv_files[0])
    permissions_headers = load_headers(header_csv_files[1])
    merged_headers = load_headers(header_csv_files[2])
    api_headers = load_headers(header_csv_files[3])

    api_files_dir = os.path.join(input_dir, "APIs")
    intent_permission_files_dir = os.path.join(input_dir, "intent_permission")
    for json_file in os.listdir(api_files_dir):
        if json_file.endswith("_API.json"):
            json_file_path = os.path.join(api_files_dir, json_file)
            with open(json_file_path, "r") as file:
                api_data = json.load(file)
            api_vector = vectorize_data(
                api_data, api_headers, use_count=False, convert_to_dict=convert_to_dict)
            print(api_vector)
            api_vector["class"] = None
            logger.info(
                f"{bcolors.OKGREEN}API Vector for {json_file}:{bcolors.ENDC} \n{bcolors.OKBLUE} {dict(list(api_vector.items())[:10])}{bcolors.ENDC}\n")
            results.append(api_vector)

    for json_file in os.listdir(intent_permission_files_dir):

        if json_file.endswith(".json"):

            json_file_path = os.path.join(
                intent_permission_files_dir, json_file)
            with open(json_file_path, "r") as file:
                intent_permission_data = json.load(file)

            # Intents

            intents_vector = vectorize_data(
                intent_permission_data["intents"], intents_headers, convert_to_dict=convert_to_dict)
            intents_vector["class"] = None
            logger.info(
                f"{bcolors.OKGREEN}\nIntents Vector for {json_file}:{bcolors.ENDC} \n{bcolors.OKBLUE}{dict(list(intents_vector.items())[:10])}\n{bcolors.ENDC}\n")
            results.append(intents_vector)
            # Permissions
            permissions_vector = vectorize_data(
                intent_permission_data["permissions"], permissions_headers, convert_to_dict=convert_to_dict)
            permissions_vector["class"] = None
            logger.info(
                f"{bcolors.OKGREEN}\nPermissions Vector for {json_file}:{bcolors.ENDC}  \n{bcolors.OKBLUE} {dict(list(permissions_vector.items())[:10])}\n{bcolors.ENDC}\n")
            results.append(permissions_vector)
            # Merged
            merged_vector = vectorize_data(
                {**intent_permission_data["intents"], **intent_permission_data["permissions"]}, merged_headers, convert_to_dict=convert_to_dict)
            merged_vector["class"] = None
            logger.info(
                f"{bcolors.OKGREEN}\nMerged Vector for {json_file}:{bcolors.ENDC} \n{bcolors.OKBLUE} {dict(list(merged_vector.items())[:10])}\n{bcolors.ENDC}\n")
            results.append(merged_vector)

            if save_to_file:
                file_name = f"{input_dir}//{json_file[:-5]}_vector.json"
                with open(file_name, "w") as file:
                    # Save as json with matching keys
                    file.write(str('{\n"API_Vector\":'))
                    file.write(str(json.dumps(api_vector)))
                    file.write(str("\n ,"))
                    file.write(str("\n"))
                    file.write(str('\n"Intents_Vector\":'))
                    file.write(str(json.dumps(intents_vector)))
                    file.write(str("\n ,"))
                    file.write(str("\n"))
                    file.write(str('\n"Permissions_Vector\":'))
                    file.write(str(json.dumps(permissions_vector)))
                    file.write(str("\n ,"))
                    file.write(str('\n"Merged_Vector\":'))
                    file.write(str(json.dumps(merged_vector)))
                    file.write(str("\n }"))
                with open(file_name, "r+") as file:
                    json_object = json.load(file)
                    json_formatted_str = json.dumps(json_object, indent=2)
                    file.seek(0)  # sets  point at the beginning of the file
                    file.truncate()

                    file.write(json_formatted_str)

    return results


if __name__ == "__main__":
    # You can replace these paths with the paths to your CSV files
    header_csv_files = [
        r"src\dataset_heads\ChimeraDatasetIntent_headers.csv",
        r"src\dataset_heads\ChimeraDatasetPermission_headers.csv",
        r"src\dataset_heads\ChimeraDatasetMerged_headers.csv",
        r"src\dataset_heads\mapped_heads.csv"
    ]

    if not check_csv_files_exist(header_csv_files):
        error_logger.error("Please Build the CSV files first.")
        exit(1)

    header_lists = [load_headers(csv_file) for csv_file in header_csv_files]

    parser = argparse.ArgumentParser(
        description="Generate vectorized arrays from JSON files.")
    parser.add_argument(
        "-i", "--input_dir", help="Path to the input directory", type=str, required=True)
    parser.add_argument(
        "-d", "--convert_to_dict", help="Whether to convert the output into a dictionary with matching keys (default: True)", type=bool, default=True)
    parser.add_argument(
        "-s", "--save_to_file", help="Whether to save the output to a file (default: False)", type=bool, default=False)

    args = parser.parse_args()

    process_files(args.input_dir, args.convert_to_dict, args.save_to_file)
